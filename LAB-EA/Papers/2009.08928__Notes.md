
# A Study of Genetic Algorithms for Hyperparameter Optimization of Neural Networks in Machine Translation

[Abstract](https://arxiv.org/abs/2009.08928), [PDF](https://arxiv.org/pdf/2009.08928.pdf)

## Authors

- Keshav Ganapathy

## Abstract

With neural networks having demonstrated their versatility and benefits, the need for their optimal performance is as prevalent as ever. A defining characteristic, hyperparameters, can greatly affect its performance. Thus engineers go through a process, tuning, to identify and implement optimal hyperparameters. That being said, excess amounts of manual effort are required for tuning network architectures, training configurations, and preprocessing settings such as Byte Pair Encoding (BPE). In this study, we propose an automatic tuning method modeled after Darwin's Survival of the Fittest Theory via a Genetic Algorithm (GA). Research results show that the proposed method, a GA, outperforms a random selection of hyperparameters.

## Comments



## Source Code

Official Code



Community Code

- [https://paperswithcode.com/paper/a-study-of-genetic-algorithms-for](https://paperswithcode.com/paper/a-study-of-genetic-algorithms-for)

## Bibtex

```tex
@misc{ganapathy2020study,
      title={A Study of Genetic Algorithms for Hyperparameter Optimization of Neural Networks in Machine Translation}, 
      author={Keshav Ganapathy},
      year={2020},
      eprint={2009.08928},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}
```

## Notes

Type your reading notes here...

